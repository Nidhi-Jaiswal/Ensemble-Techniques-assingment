{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e8c409",
   "metadata": {},
   "source": [
    "Q1>> Can we use Bagging for regression problems?\n",
    "\n",
    "Yes, — Bagging (Bootstrap Aggregating) can be used for regression problems!\n",
    "\n",
    "In fact, it's a very popular and effective technique in regression tasks.\n",
    "### How Bagging Works for Regression:\n",
    "**Bootstrap Sampling:** Multiple subsets of the training data are created using random sampling with replacement.\n",
    "\n",
    "**Base Learners:** Each subset is used to train a separate regression model (commonly, Decision Trees).\n",
    "\n",
    "**Aggregation:** For regression, the final prediction is typically the average of all individual model predictions.\n",
    "### Why Use It:\n",
    "    Reduces variance (helps avoid overfitting)\n",
    "\n",
    "    Improves stability and accuracy\n",
    "\n",
    "    Especially helpful when your base model is high-variance, like decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae78db3",
   "metadata": {},
   "source": [
    "Q2>> What is the difference between multiple model training and single model training?\n",
    "\n",
    "### Single Model Training\n",
    "**Definition:** One model is trained on the entire dataset\n",
    "\n",
    "**Complexity:**\tSimpler and easier to interpret\n",
    "\n",
    "**Training Time:**\tUsually faster\n",
    "\n",
    "**Performance:** May have higher bias or variance\n",
    "\n",
    "**Overfitting Risk:** More prone to overfitting (esp. with complex models)\n",
    "\n",
    "**Examples:** Linear Regression, Decision Tree\n",
    "\n",
    "**Variance Reduction:**\tNo mechanism to reduce variance\n",
    "\n",
    "**Use Case:** When simplicity and interpretability are priorities\n",
    "\n",
    "### Multiple Model Training (Ensembles)\n",
    "**Definition:** Multiple models are trained, and their outputs are combined\n",
    "\n",
    "**Complexity:**\tMore complex and harder to interpret\n",
    "\n",
    "**Training Time:**\tSlower due to training multiple models\n",
    "\n",
    "**Performance:** Often improves accuracy and robustness\n",
    "\n",
    "**Overfitting Risk:** Reduced risk due to averaging or voting\n",
    "\n",
    "**Examples:** Random Forest, Bagging, Boosting, Voting\n",
    "\n",
    "**Variance Reduction:**\tReduces variance (Bagging) or bias (Boosting)\n",
    "\n",
    "**Use Case:** When high accuracy and stability are needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3bb3a8",
   "metadata": {},
   "source": [
    "Q3>> Explain the concept of feature randomness in Random Forest.\n",
    "\n",
    "In Random Forests, each individual decision tree is trained not only on a random subset of the data (rows) (thanks to bagging) but also on a random subset of the features (columns) at each split in the tree. This is called feature randomness.\n",
    "\n",
    "**Why Use Feature Randomness?**\n",
    "\n",
    "    In standard decision trees, the model always looks for the best feature to split the data at each node.\n",
    "\n",
    "    In Random Forests, instead of considering all features, the tree only considers a random selection of features at each            split.\n",
    "\n",
    "    This forces each tree to learn differently, increasing diversity among the trees in the forest.\n",
    "    \n",
    "**Example:**\n",
    "\n",
    "    Suppose you have 100 features.\n",
    "\n",
    "    When training each tree, you might randomly pick √100 = 10 features to consider at each split.\n",
    "\n",
    "    This randomness makes sure trees are less similar to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9814d276",
   "metadata": {},
   "source": [
    "Q4>> What is OOB (Out-of-Bag) Score?\n",
    "\n",
    "The OOB (Out-of-Bag) Score is a built-in way to estimate the performance of Bagging models, especially Random Forests, without needing a separate validation set.\n",
    "\n",
    "When using Bagging, each model (like a decision tree in Random Forest) is trained on a bootstrap sample — a random sample with replacement from the training data.\n",
    "\n",
    "    Because of this, on average, about 63% of the original data is included in each bootstrap sample.\n",
    "\n",
    "    The remaining ~37% of data is not seen by that particular model — these are called the Out-of-Bag samples.\n",
    "\n",
    "The OOB score uses these left-out samples to test the model’s performance.\n",
    "\n",
    "**How it Works:**\n",
    "\n",
    "    For each data point in the training set:\n",
    "\n",
    "    It is not included in the bootstrap sample for some of the trees.\n",
    "\n",
    "    Those trees that didn't train on that point can be used to predict it.\n",
    "\n",
    "    The final OOB prediction is the average (for regression) or majority vote (for classification) of those trees.\n",
    "\n",
    "    The OOB score is computed by comparing these predictions to the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f20ba0",
   "metadata": {},
   "source": [
    "Q5>> How can you measure the importance of features in a Random Forest model?\n",
    "\n",
    "Measuring feature importance in a Random Forest model helps us understand which features have the most influence on predictions.\n",
    "\n",
    "**1. Mean Decrease in Impurity (MDI) — a.k.a. Gini Importance**\n",
    "\n",
    "    This is the default method in scikit-learn.\n",
    "\n",
    "    Every time a feature is used to split a node, the impurity (e.g., Gini for classification or MSE for regression) decreases.\n",
    "\n",
    "    These decreases are accumulated and averaged over all trees in the forest.\n",
    "\n",
    "    The more a feature decreases impurity, the more important it is.\n",
    "    \n",
    "**2. Permutation Importance (Model-Agnostic)**\n",
    "\n",
    "    Randomly shuffle the values of a feature and see how much the model performance drops.\n",
    "\n",
    "    The bigger the drop, the more important the feature is.\n",
    "\n",
    "    More reliable than MDI, especially when features are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4ae13",
   "metadata": {},
   "source": [
    "Q6>>  Explain the working principle of a Bagging Classifier.\n",
    "\n",
    "Bagging stands for Bootstrap Aggregating.\n",
    "\n",
    "It’s an ensemble learning method designed to improve the stability and accuracy of machine learning algorithms — especially high-variance models like decision trees.\n",
    "\n",
    "### How Does a Bagging Classifier Work?\n",
    "Here’s the process:\n",
    "\n",
    "**1. Bootstrap Sampling:**\n",
    "\n",
    "    From the original training data of size n, it creates multiple random subsets (with replacement).\n",
    "\n",
    "    Each subset is the same size as the original data but may have duplicates (because of replacement).\n",
    "\n",
    "**2. Train Base Models:**\n",
    "\n",
    "    A base classifier (e.g., Decision Tree) is trained independently on each bootstrapped subset.\n",
    "\n",
    "    All base models learn slightly different patterns due to the differences in data samples.\n",
    "\n",
    "**3. Make Predictions:**\n",
    "\n",
    "    Each trained model gives its own prediction for a given input.\n",
    "\n",
    "**4. Aggregate Predictions (Voting):**\n",
    "\n",
    "    For classification, it uses majority voting:\n",
    "      → The class that appears most frequently among the models is chosen.\n",
    "\n",
    "    For regression, it would take the average of predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c0a9c",
   "metadata": {},
   "source": [
    "Q7>> How do you evaluate a Bagging Classifier’s performance?\n",
    "\n",
    "Evaluating a Bagging Classifier’s performance involves checking how well it predicts on unseen data, using standard classification metrics.\n",
    "\n",
    "**1. Split the Data**\n",
    "\n",
    "First, you need to separate your dataset into:\n",
    "\n",
    "    Training set (to train the model)\n",
    "\n",
    "    Test/Validation set (to evaluate performance)\n",
    "\n",
    "Or use cross-validation for a more robust estimate.\n",
    "\n",
    "**2. Common Evaluation Metrics**\n",
    "\n",
    "Accuracy:\tOverall percentage of correct predictions\n",
    "\n",
    "Precision:\tOf predicted positives, how many are truly positive\n",
    "\n",
    "Recall (Sensitivity):\tOf actual positives, how many were correctly predicted\n",
    "\n",
    "F1 Score:\tHarmonic mean of precision and recall (balances both)\n",
    "\n",
    "Confusion Matrix:\tShows TP, FP, FN, TN — gives detailed class-level insight\n",
    "\n",
    "ROC-AUC Score:\tMeasures model's ability to distinguish between classes\n",
    "\n",
    "**3. (Optional) Use OOB Score**\n",
    "\n",
    "If you enabled oob_score=True when creating the model:\n",
    "                     \n",
    "                     print(\"OOB Score:\", model.oob_score_)\n",
    "\n",
    "It gives a built-in estimate of generalization accuracy using Out-of-Bag samples (no need for separate test set)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32299f",
   "metadata": {},
   "source": [
    "Q8>> How does a Bagging Regressor work?\n",
    "\n",
    "### How It Works — Step-by-Step:\n",
    "**1. Bootstrap Sampling (Data Randomness)**\n",
    "\n",
    "    Create multiple subsets of the training data by sampling with replacement (bootstrapping).\n",
    "\n",
    "    Each subset is used to train a separate regression model (usually Decision Trees, but you can choose others too).\n",
    "\n",
    "**2. Train Base Regressors**\n",
    "\n",
    "    Each model learns slightly different patterns from its bootstrapped sample.\n",
    "\n",
    "    The base models are trained in parallel, independently of each other.\n",
    "\n",
    "**3. Predict and Aggregate (Averaging)**\n",
    "\n",
    "    For a new input, each trained regressor makes a prediction.\n",
    "\n",
    "    The final output is the average of all predictions:\n",
    "\n",
    "                                        𝑦^ = 1/𝑛 n∑𝑖=1 𝑦^𝑖\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf4e05",
   "metadata": {},
   "source": [
    "Q9>> What is the main advantage of ensemble techniques?\n",
    "\n",
    "The main advantage of ensemble techniques is:\n",
    "### Improved Model Performance through Combining Multiple Models\n",
    "By combining multiple individual models (often called base learners), ensemble techniques can:\n",
    "\n",
    "**Reduce Overfitting (Variance)**\n",
    "\n",
    "    Especially useful with high-variance models (like decision trees in bagging).\n",
    "\n",
    "    Ensemble smooths out the noise by averaging many models → more stable predictions.\n",
    "\n",
    "**Reduce Underfitting (Bias)**\n",
    "\n",
    "    Techniques like Boosting can correct errors made by earlier models, reducing bias.\n",
    "\n",
    "    The ensemble \"focuses\" on hard-to-predict cases.\n",
    "\n",
    "**Increase Accuracy & Robustness**\n",
    "\n",
    "    Ensembles usually outperform single models in terms of prediction accuracy.\n",
    "\n",
    "    More resistant to data noise, outliers, and changes in the dataset.\n",
    "\n",
    "**Balance Bias-Variance Trade-off**\n",
    "\n",
    "    Smart combinations (e.g,Random Forests or Gradient Boosting) can find a sweet spot between underfitting and overfitting.\n",
    "\n",
    "**Greater Generalization to Unseen Data**\n",
    "\n",
    "    Ensembles generalize better by learning from different perspectives (samples, features, or errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a612d0",
   "metadata": {},
   "source": [
    "Q10>> What is the main challenge of ensemble methods?\n",
    "\n",
    "While ensemble methods are powerful, they do come with their own set of challenges. The main challenge is:\n",
    "### Increased Complexity & Reduced Interpretability\n",
    "Here's why:\n",
    "\n",
    "**Harder to Interpret:**  It's difficult to understand how the final prediction is made, especially when combining dozens or hundreds of models.\n",
    "\n",
    "**Slower Training & Prediction:**\tTraining multiple models (especially deep trees or neural nets) takes more time and resources.\n",
    "\n",
    "**Storage & Deployment Complexity:**\tSaving, loading, and deploying ensemble models (e.g., Random Forests, Gradient Boosting) can be bulky.\n",
    "\n",
    "**Risk of Overfitting (Boosting)**\tBoosting methods can overfit if not properly regularized or if too many weak learners are added.\n",
    "\n",
    "**Hyperparameter Tuning:**\tEnsembles often have many hyperparameters (e.g., number of estimators, depth, learning rate) that require tuning.\n",
    "\n",
    "**Not Always Better:**\tIf your base models are already strong or your dataset is small and clean, ensembles might not provide significant gains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592c6ef",
   "metadata": {},
   "source": [
    "Q11>> Explain the key idea behind ensemble techniques.\n",
    "\n",
    "Instead of relying on a single model, ensemble techniques combine multiple models to make a final prediction — and this combination is usually more accurate, stable, and generalizable than any single model alone.\n",
    "\n",
    "### Why It Works:\n",
    "**Diversity:**\tDifferent models make different errors. Combining them reduces the chance that all make the same mistake.\n",
    "\n",
    "**Averaging/Voting:**\tAggregating predictions (by majority vote or averaging) smooths out individual model errors.\n",
    "\n",
    "**Error Compensation:**\t Weak models (like shallow decision trees) can be combined to form a strong one (as in boosting).\n",
    "\n",
    "**Bias-Variance Trade-off:**\tEnsembles balance underfitting and overfitting, improving generalization to new data.\n",
    "\n",
    "The key idea behind ensemble techniques is that a group of diverse, less accurate models can come together to produce a single, more accurate and robust model — just like how a team can outperform an individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0440208",
   "metadata": {},
   "source": [
    "Q12>> What is a Random Forest Classifier?\n",
    "\n",
    "A Random Forest Classifier is an ensemble learning algorithm used for classification tasks. It builds a “forest” of decision trees and combines their predictions to improve accuracy and prevent overfitting.\n",
    "\n",
    "    It uses Bagging (Bootstrap Aggregation) + Feature Randomness to grow many decision trees and then uses majority voting to        make final predictions.\n",
    "\n",
    "### How It Works (Step-by-Step):\n",
    "**Bootstrap Sampling:**\n",
    "\n",
    "    Create multiple random samples of the training data (with replacement).\n",
    "\n",
    "**Train Multiple Decision Trees:**\n",
    "\n",
    "    For each sample, train a decision tree.\n",
    "\n",
    "    At each split, only a random subset of features is considered (adds more randomness and decorrelation between trees).\n",
    "\n",
    "**Make Predictions:**\n",
    "\n",
    "    Each tree predicts a class label.\n",
    "\n",
    "    The final prediction is the class most voted by the trees (majority vote)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de62ecce",
   "metadata": {},
   "source": [
    "Q13>> What are the main types of ensemble techniques?\n",
    "\n",
    "Ensemble techniques can be broadly categorized into three main types, each with its own approach to combining multiple models. Here’s a breakdown of the key types:\n",
    "### 1. Bagging (Bootstrap Aggregating)\n",
    "**Key Idea:**\n",
    "\n",
    "Bagging aims to reduce variance by training multiple models on different random subsets of the data and then averaging their predictions (for regression) or using majority voting (for classification).\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "    Bootstrap Sampling: Randomly sample subsets of the training data with replacement.\n",
    "\n",
    "    Parallel Training: Train multiple models (often decision trees) independently on these subsets.\n",
    "\n",
    "    Aggregate Results: Combine predictions through averaging (regression) or voting (classification).\n",
    "\n",
    "**Example Algorithms:**\n",
    "\n",
    "    Random Forest (most common example)\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "    Reduces overfitting.\n",
    "\n",
    "    Works well with high-variance models (like decision trees).\n",
    "\n",
    "### 2.  Boosting\n",
    "**Key Idea:**\n",
    "\n",
    "Boosting aims to reduce bias by sequentially training models where each model tries to correct the errors made by the previous one. Boosting adjusts the weights of incorrectly predicted instances to focus learning on hard-to-predict cases.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "    Sequential Learning: Models are trained one after another, with each model correcting the errors of the previous one.\n",
    "\n",
    "    Weighted Voting: Each model’s contribution to the final prediction is weighted based on its performance.\n",
    "\n",
    "**Example Algorithms:**\n",
    "\n",
    "    AdaBoost\n",
    "\n",
    "    Gradient Boosting (e.g., XGBoost, LightGBM, CatBoost)\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "    Can handle imbalanced data well.\n",
    "\n",
    "    Tends to produce highly accurate models.\n",
    "\n",
    "    Often works well even with weak base learners (e.g., shallow decision trees).\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "    More prone to overfitting if not tuned properly.\n",
    "\n",
    "    Computationally more expensive than Bagging.\n",
    "\n",
    "### 3. Stacking (Stacked Generalization)\n",
    "**Key Idea:**\n",
    "\n",
    "Stacking combines different models (possibly from different types) to form a meta-model. The meta-model learns how to best combine the predictions of the base models.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "    Train Base Models: Train multiple different models (e.g., decision trees, logistic regression, SVM).\n",
    "\n",
    "    Meta-Model: Use the predictions of these base models as inputs to a meta-model (a higher-level model like linear regression      or another classifier).\n",
    "\n",
    "    Final Prediction: The meta-model combines the base models’ predictions to make the final prediction.\n",
    "\n",
    "**Example Algorithms:**\n",
    "\n",
    "    Stacked Generalization (typically uses diverse base learners)\n",
    "\n",
    "    Blending (a simpler form of stacking)\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "    Often yields better performance than individual models.\n",
    "\n",
    "    Can combine the strengths of different types of models.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "    Requires careful model selection and training.\n",
    "\n",
    "    More complex and computationally expensive to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9faece",
   "metadata": {},
   "source": [
    "Q14>> What is ensemble learning in machine learning?\n",
    "\n",
    "Ensemble learning refers to a technique in machine learning where multiple models (often called base learners or weak learners) are combined to solve a problem and improve the performance of a single model.\n",
    "\n",
    "The key idea is that by combining several models, the ensemble can make more accurate predictions than any individual model. This is because the errors made by one model can be corrected by others in the ensemble, leading to better overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cbef4",
   "metadata": {},
   "source": [
    "Q15>> When should we avoid using ensemble methods?\n",
    "\n",
    "While ensemble methods are powerful, there are certain scenarios where it might not be the best choice. Here are some key situations where avoiding ensemble methods makes sense:\n",
    "### 1. Small Datasets\n",
    "**Why Avoid:** Ensemble methods tend to shine when there's a lot of data because they aggregate information from multiple models. With small datasets, the advantage of combining multiple models diminishes, and the computational cost of training multiple models may outweigh the benefits.\n",
    "\n",
    "**Alternative:** A single, well-tuned model may perform just as well or even better on smaller datasets.\n",
    "\n",
    "### 2. High Computational Cost/Resources\n",
    "**Why Avoid:** Ensemble methods, especially boosting and bagging algorithms like Random Forest or XGBoost, can be computationally expensive. They require training multiple models, which can significantly increase both training time and memory usage, especially with large datasets.\n",
    "\n",
    "**Alternative:** If computational resources are limited or time is a concern, simpler models like Logistic Regression, SVM, or a single Decision Tree might be better.\n",
    "\n",
    "### 3. Low Complexity Problem\n",
    "**Why Avoid:** If the problem is simple (e.g., linear relationships, well-separated classes, etc.), the additional complexity introduced by ensembles is unnecessary. For example, using a Random Forest or Gradient Boosting might be overkill if a Logistic Regression or Decision Tree already provides sufficient accuracy.\n",
    "\n",
    "**Alternative:** In cases of low complexity, a single model is likely to perform just as well with less computational overhead and easier interpretability.\n",
    "\n",
    "### 4. When Interpretability is Crucial\n",
    "**Why Avoid:** Ensemble methods, especially those that aggregate a large number of decision trees like Random Forests or XGBoost, are difficult to interpret compared to simpler models. In high-stakes applications where you need to understand and explain the model’s decision-making process (e.g., healthcare, finance, legal), ensembles may be less suitable.\n",
    "\n",
    "**Alternative:** Simpler models such as Logistic Regression, Decision Trees, or Linear Regression can provide better transparency and ease of explanation.\n",
    "\n",
    "### 5. Risk of Overfitting in Noisy Data (Especially Boosting)\n",
    "**Why Avoid:** Some ensemble methods like Boosting (e.g., AdaBoost, XGBoost) can overfit if the base models are too complex or if there’s a lot of noise in the data. Since boosting focuses on correcting errors of previous models, it may unintentionally learn to fit noisy or irrelevant patterns in the data.\n",
    "\n",
    "**Alternative:** In cases of noisy data, simpler models or bagging methods (like Random Forest) may provide better generalization, as they focus on reducing variance rather than bias.\n",
    "\n",
    "### 6. When You Don’t Have Enough Diverse Base Models\n",
    "**Why Avoid:** For ensemble methods (like stacking), it’s crucial that the base models are diverse. If the base models are too similar (e.g., multiple decision trees or logistic regressions), the ensemble won’t provide much benefit. You need diversity for the ensemble to correct for different types of errors.\n",
    "\n",
    "**Alternative:** Ensure your base models are diverse (e.g., using a mix of decision trees, SVMs, logistic regression, etc.) or stick to simpler models when diversity is hard to achieve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726e91e0",
   "metadata": {},
   "source": [
    "Q16>> How does Bagging help in reducing overfitting?\n",
    "\n",
    "Bagging (short for Bootstrap Aggregating) helps in reducing overfitting by training multiple models on different subsets of the training data and combining their predictions. Here's how it works to reduce overfitting:\n",
    "\n",
    "**Bootstrap Sampling:**\n",
    "\n",
    "Bagging involves creating multiple bootstrap samples (random subsets of the original training data) by sampling with replacement.\n",
    "\n",
    "**Key Benefit:** By training each model on a slightly different subset of data, the model is less likely to overfit to specific noise or outliers present in the training set.\n",
    "\n",
    "**Model Averaging:**\n",
    "\n",
    "Instead of relying on a single model's prediction, Bagging aggregates predictions from all the models in the ensemble (e.g., voting for classification, averaging for regression).\n",
    "\n",
    "**Key Benefit:** The final output becomes more stable and less sensitive to fluctuations or noise in the data, leading to reduced overfitting. This process smooths out the individual model’s errors.\n",
    "\n",
    "**Reduced Variance:**\n",
    "\n",
    "Bagging lowers the variance of the model. High-variance models (like decision trees) tend to overfit by fitting closely to the training data, especially if the data is noisy.\n",
    "\n",
    "**Key Benefit:** By training multiple models on different subsets of the data and averaging the results, Bagging reduces the model’s sensitivity to small changes or noise in the training data, thereby reducing overfitting.\n",
    "\n",
    "**Summary:** Bagging reduces overfitting primarily by training multiple models on different data subsets and combining their results. This aggregation process helps to smooth out the errors and reduces the model’s sensitivity to specific noise or fluctuations in the training data, which can lead to better generalization and less overfitting.\n",
    "\n",
    "If you're working with high-variance models like decision trees, Bagging (such as Random Forest) can be particularly effective!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380da0a",
   "metadata": {},
   "source": [
    "Q17>> Why is Random Forest better than a single Decision Tree?\n",
    "\n",
    "A Random Forest is generally better than a single Decision Tree because it combines the power of multiple trees to make more accurate, stable, and generalizable predictions. Here's a breakdown of why Random Forest outperforms a single Decision Tree:\n",
    "### 1. Reduces Overfitting (Better Generalization)\n",
    "**Single Decision Tree:**\n",
    "\n",
    "    Tends to overfit the training data, especially if it grows deep (complex tree).\n",
    "\n",
    "    Captures noise along with patterns, leading to poor performance on unseen data.\n",
    "\n",
    "**Random Forest:**\n",
    "\n",
    "    Combines the output of many trees trained on different subsets of the data and random features.\n",
    "\n",
    "    Averages out the noise and focuses on the true patterns → less overfitting, better generalization.\n",
    "\n",
    "### 2. Adds Randomness for Diversity\n",
    "Random Forest adds randomness in two ways:\n",
    "\n",
    "    Bootstrap sampling: Each tree is trained on a random subset of the data (sampling with replacement).\n",
    "\n",
    "    Feature randomness: At each split, it considers only a random subset of features.\n",
    "\n",
    "This diversity among trees reduces the chance that all trees make the same mistake, increasing overall robustness.\n",
    "### 3. Improved Accuracy\n",
    "    A single decision tree might have high bias or high variance, depending on how deep it is.\n",
    "\n",
    "    A Random Forest typically finds a better bias-variance tradeoff, leading to higher accuracy on test data.\n",
    "\n",
    "### 4. Stability (Less Sensitive to Noise)\n",
    "    Single trees are very sensitive to data fluctuations—small changes in the data can lead to a completely different tree.\n",
    "\n",
    "    Random Forest, by averaging over many trees, becomes more stable and less sensitive to outliers or noise in the data.\n",
    "\n",
    "### 5. Feature Importance\n",
    "    Random Forests can rank features by importance, giving insights into which variables are most useful for prediction.\n",
    "\n",
    "    A single tree may overemphasize certain features based on a particular data split.\n",
    "\n",
    "**Conclusion:**  Random Forest is better because it reduces overfitting, increases accuracy, and is more robust to noisy data. It's one of the most powerful and widely used ensemble methods for classification and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b1381",
   "metadata": {},
   "source": [
    "Q18>>  What is the role of bootstrap sampling in Bagging?\n",
    "\n",
    "Bootstrap sampling is a key component of Bagging (Bootstrap Aggregating) — it's what makes Bagging work effectively.\n",
    "\n",
    "Bootstrap sampling is the process of randomly selecting data points with replacement from the original dataset to create multiple new training datasets (called bootstrap samples).\n",
    "\n",
    "Each of these samples is the same size as the original dataset but may include some repeated records and miss others.\n",
    "### How It Works in Bagging:\n",
    "    Suppose you have a training dataset of N samples.\n",
    "\n",
    "    Bagging generates k new training datasets (bootstrap samples), each by randomly picking N samples with replacement.\n",
    "\n",
    "    A separate model (like a decision tree) is trained on each bootstrap sample.\n",
    "\n",
    "    Final prediction is made by averaging (for regression) or majority voting (for classification) across all the models.\n",
    " \n",
    " **Analogy:**\n",
    " \n",
    "Think of bootstrap sampling like asking different groups of people (each chosen randomly from the same population) to solve a problem. Each group might reach slightly different conclusions, but combining their opinions usually gives a more reliable answer than relying on one group alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fac5fe",
   "metadata": {},
   "source": [
    "Q19>> What are some real-world applications of ensemble techniques?\n",
    "\n",
    "Ensemble techniques are widely used in real-world applications because they improve model accuracy, robustness, and generalization. Here's a breakdown of some common real-world use cases across different industries:\n",
    "\n",
    "### 1. Fraud Detection (Banking & Finance)\n",
    "\n",
    "**Why ensemble?:** Fraud patterns are complex, subtle, and constantly evolving. Ensembles handle this complexity well.\n",
    "\n",
    "**Use case:** Detecting credit card fraud, insurance claim fraud, transaction anomalies.\n",
    "\n",
    "**Technique used:** Random Forest, XGBoost, LightGBM.\n",
    "\n",
    "### 2. Medical Diagnosis (Healthcare)\n",
    "**Why ensemble?:** Medical data is often high-dimensional and noisy. Ensemble methods improve diagnostic accuracy and reduce false positives.\n",
    "\n",
    "**Use case:** Predicting disease risk (e.g., cancer detection, diabetes prediction), patient readmission.\n",
    "\n",
    "**Technique used:** Gradient Boosting, Bagging, Random Forest.\n",
    "\n",
    "### 3. Recommendation Systems (E-commerce & Entertainment)\n",
    "**Why ensemble?:** Combining different models (e.g., content-based + collaborative filtering) helps generate more personalized recommendations.\n",
    "\n",
    "**Use case:** Product recommendations on Amazon, movie suggestions on Netflix or YouTube.\n",
    "\n",
    "**Technique used:** Model stacking, hybrid ensembles.\n",
    "\n",
    "### 4.  Sentiment Analysis & NLP (Social Media, Marketing)\n",
    "**Why ensemble?:** Text data can be ambiguous. Ensembles improve robustness in interpreting human language.\n",
    "\n",
    "**Use case:** Analyzing customer reviews, brand sentiment monitoring.\n",
    "\n",
    "**Technique used:** Voting classifiers, ensemble of transformers, Random Forest with TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f733e4ca",
   "metadata": {},
   "source": [
    "Q20>> What is the difference between Bagging and Boosting?\n",
    "\n",
    "Bagging and Boosting are both powerful ensemble techniques, but they work in fundamentally different ways.\n",
    "### Bagging\n",
    "**Goal:**\tReduce variance\t\n",
    "\n",
    "**Model Training:**\tModels trained independently\n",
    "\n",
    "**Data Sampling:**\tUses bootstrap samples (with replacement)\t\n",
    "\n",
    "**Model Focus:**\tTreat all models equally\n",
    "\n",
    "**Overfitting Risk:**\tLower\t\n",
    "\n",
    "**Speed:**\tFaster (parallelizable)\t\n",
    "\n",
    "**Best For:**\tHigh-variance models (e.g., decision trees)\n",
    "\n",
    "**Examples:**\tRandom Forest, BaggingClassifier\n",
    "\n",
    "### Boosting\n",
    "**Goal:**\tReduce bias (and then variance)\n",
    "\n",
    "**Model Training:**\t Models trained sequentially\n",
    "\n",
    "**Data Sampling:**\tUses entire dataset (with weighted samples)\t\n",
    "\n",
    "**Model Focus:**\tEach model focuses on errors of the previous one\n",
    "\n",
    "**Overfitting Risk:**\tHigher (needs careful tuning)\t\n",
    "\n",
    "**Speed:**\tSlower (sequential process)\t\n",
    "\n",
    "**Best For:**\tHigh-bias problems\n",
    "\n",
    "**Examples:**\tAdaBoost, Gradient Boosting, XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909750f7",
   "metadata": {},
   "source": [
    "# Practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b77ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#1. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load sample dataset (Iris)\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a base model (Decision Tree)\n",
    "base_model = DecisionTreeClassifier()\n",
    "\n",
    "# Create Bagging Classifier using Decision Trees\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_model, n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "# Print model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Bagging Classifier Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a0ac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor Mean Squared Error: 2987.01\n"
     ]
    }
   ],
   "source": [
    "#2. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Load a sample regression dataset (Diabetes dataset)\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Create base regressor (Decision Tree)\n",
    "base_regressor = DecisionTreeRegressor()\n",
    "\n",
    "# 4. Create Bagging Regressor\n",
    "bagging_reg = BaggingRegressor(base_estimator=base_regressor, n_estimators=50, random_state=42)\n",
    "\n",
    "# 5. Train the model\n",
    "bagging_reg.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions\n",
    "y_pred = bagging_reg.predict(X_test)\n",
    "\n",
    "# 7. Evaluate using Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Bagging Regressor Mean Squared Error: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a051fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "\n",
      "                    Feature  Importance\n",
      "7       mean concave points    0.141934\n",
      "27     worst concave points    0.127136\n",
      "23               worst area    0.118217\n",
      "6            mean concavity    0.080557\n",
      "20             worst radius    0.077975\n",
      "22          worst perimeter    0.074292\n",
      "2            mean perimeter    0.060092\n",
      "3                 mean area    0.053810\n",
      "26          worst concavity    0.041080\n",
      "0               mean radius    0.032312\n",
      "13               area error    0.029538\n",
      "21            worst texture    0.018786\n",
      "25        worst compactness    0.017539\n",
      "10             radius error    0.016435\n",
      "28           worst symmetry    0.012929\n",
      "12          perimeter error    0.011770\n",
      "24         worst smoothness    0.011769\n",
      "1              mean texture    0.011064\n",
      "5          mean compactness    0.009216\n",
      "19  fractal dimension error    0.007135\n",
      "29  worst fractal dimension    0.006924\n",
      "4           mean smoothness    0.006223\n",
      "14         smoothness error    0.005881\n",
      "16          concavity error    0.005816\n",
      "15        compactness error    0.004596\n",
      "18           symmetry error    0.004001\n",
      "17     concave points error    0.003382\n",
      "8             mean symmetry    0.003278\n",
      "11            texture error    0.003172\n",
      "9    mean fractal dimension    0.003140\n"
     ]
    }
   ],
   "source": [
    "#3. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# 2. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train a Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# 5. Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 6. Print feature importances\n",
    "print(\"Feature Importances:\\n\")\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a47ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor MSE: 5697.79\n",
      "Random Forest Regressor MSE: 2859.64\n"
     ]
    }
   ],
   "source": [
    "#4. Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Load sample regression dataset\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train a single Decision Tree Regressor\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_preds = tree_model.predict(X_test)\n",
    "tree_mse = mean_squared_error(y_test, tree_preds)\n",
    "\n",
    "# 4. Train a Random Forest Regressor\n",
    "forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_model.fit(X_train, y_train)\n",
    "forest_preds = forest_model.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_test, forest_preds)\n",
    "\n",
    "# 5. Print and compare MSE scores\n",
    "print(f\"Decision Tree Regressor MSE: {tree_mse:.2f}\")\n",
    "print(f\"Random Forest Regressor MSE: {forest_mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c791043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-Bag (OOB) Score: 0.9548\n"
     ]
    }
   ],
   "source": [
    "#5. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Load the Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split into training and test sets (OOB only uses training data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train a Random Forest with OOB enabled\n",
    "rf_oob = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
    "rf_oob.fit(X_train, y_train)\n",
    "\n",
    "# 4. Print the OOB score\n",
    "print(f\"Out-of-Bag (OOB) Score: {rf_oob.oob_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2acb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier (SVM base) Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#6. Train a Bagging Classifier using SVM as a base estimator and print accuracy\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load sample dataset (Iris dataset)\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Create base model (SVM)\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# 4. Create Bagging Classifier using SVM as base estimator\n",
    "bagging_svm = BaggingClassifier(base_estimator=svm_model, n_estimators=50, random_state=42)\n",
    "\n",
    "# 5. Train the model\n",
    "bagging_svm.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions\n",
    "y_pred = bagging_svm.predict(X_test)\n",
    "\n",
    "# 7. Print model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Bagging Classifier (SVM base) Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3632ef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with 10 trees: Accuracy = 1.00\n",
      "Random Forest with 50 trees: Accuracy = 1.00\n",
      "Random Forest with 100 trees: Accuracy = 1.00\n",
      "Random Forest with 200 trees: Accuracy = 1.00\n",
      "Random Forest with 500 trees: Accuracy = 1.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#7. Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. List of different numbers of trees (n_estimators)\n",
    "n_trees = [10, 50, 100, 200, 500]\n",
    "\n",
    "# 4. Store accuracy for each configuration\n",
    "accuracies = []\n",
    "\n",
    "# 5. Train Random Forest with different numbers of trees and calculate accuracy\n",
    "for n in n_trees:\n",
    "    rf_model = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Random Forest with {n} trees: Accuracy = {accuracy:.2f}\")\n",
    "\n",
    "# 6. Plot accuracy vs. number of trees\n",
    "plt.plot(n_trees, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Number of Trees (n_estimators)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Random Forest Accuracy vs. Number of Trees')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a16352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier (Logistic Regression base) AUC Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#8. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# 1. Load sample dataset (Iris dataset)\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Since AUC requires binary classification, we will use only two classes (class 0 and class 1)\n",
    "X = X[y != 2]  # Select only class 0 and class 1\n",
    "y = y[y != 2]\n",
    "\n",
    "# 2. Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Create base model (Logistic Regression)\n",
    "log_reg_model = LogisticRegression()\n",
    "\n",
    "# 4. Create Bagging Classifier using Logistic Regression as base estimator\n",
    "bagging_lr = BaggingClassifier(base_estimator=log_reg_model, n_estimators=50, random_state=42)\n",
    "\n",
    "# 5. Train the model\n",
    "bagging_lr.fit(X_train, y_train)\n",
    "\n",
    "# 6. Predict probabilities (needed for AUC calculation)\n",
    "y_pred_prob = bagging_lr.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "\n",
    "# 7. Calculate AUC score\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"Bagging Classifier (Logistic Regression base) AUC Score: {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c82fa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "\n",
      "  Feature  Importance\n",
      "2     bmi    0.400000\n",
      "8      s5    0.166602\n",
      "3      bp    0.104839\n",
      "9      s6    0.071358\n",
      "6      s3    0.061730\n",
      "0     age    0.058633\n",
      "4      s1    0.049191\n",
      "5      s2    0.047138\n",
      "7      s4    0.029427\n",
      "1     sex    0.011082\n"
     ]
    }
   ],
   "source": [
    "#9. Train a Random Forest Regressor and analyze feature importance scores.\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Diabetes dataset\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# 4. Get feature importance scores\n",
    "importances = rf_regressor.feature_importances_\n",
    "\n",
    "# 5. Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 6. Print feature importances\n",
    "print(\"Feature Importances:\\n\")\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9dd887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 1.00\n",
      "Random Forest Classifier Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#10. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Create base model (Decision Tree for Bagging)\n",
    "base_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 4. Train a Bagging Classifier using Decision Trees\n",
    "bagging_model = BaggingClassifier(base_estimator=base_model, n_estimators=50, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Train a Random Forest Classifier\n",
    "random_forest_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "y_pred_rf = random_forest_model.predict(X_test)\n",
    "\n",
    "# 7. Compute accuracy for both models\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# 8. Print and compare accuracy\n",
    "print(f\"Bagging Classifier Accuracy: {accuracy_bagging:.2f}\")\n",
    "print(f\"Random Forest Classifier Accuracy: {accuracy_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c634ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Cross-Validation Score: 0.9429\n",
      "Test Set Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "#11. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Define the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 4. Define the hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],     # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5],     # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2],      # Minimum samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]       # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "# 5. Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# 6. Train the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 7. Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# 8. Print the best hyperparameters and score\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score:.4f}\")\n",
    "\n",
    "# 9. Evaluate the model with the best hyperparameters on the test set\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# 10. Calculate accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93de90de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor with 10 base estimators: MSE = 3237.53\n",
      "Bagging Regressor with 50 base estimators: MSE = 2987.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor with 100 base estimators: MSE = 2908.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor with 200 base estimators: MSE = 2854.88\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#12. Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load the Diabetes dataset\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Create base model (Decision Tree for Bagging)\n",
    "base_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# 4. List of different numbers of base estimators (n_estimators)\n",
    "n_estimators_list = [10, 50, 100, 200]\n",
    "\n",
    "# 5. Store MSE for each configuration\n",
    "mse_scores = []\n",
    "\n",
    "# 6. Train Bagging Regressor with different numbers of base estimators and calculate MSE\n",
    "for n in n_estimators_list:\n",
    "    bagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=n, random_state=42)\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    y_pred = bagging_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "    print(f\"Bagging Regressor with {n} base estimators: MSE = {mse:.2f}\")\n",
    "\n",
    "# 7. Plot MSE vs. Number of base estimators\n",
    "plt.plot(n_estimators_list, mse_scores, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Number of Base Estimators (n_estimators)')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Bagging Regressor Performance vs. Number of Base Estimators')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde76346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 1.00\n",
      "\n",
      "Misclassified Samples:\n",
      "Empty DataFrame\n",
      "Columns: [Sample Index, True Label, Predicted Label, Sample]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#13. Train a Random Forest Classifier and analyze misclassified samples.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 5. Calculate accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Classifier Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# 6. Analyze misclassified samples\n",
    "misclassified_idx = [i for i in range(len(y_test)) if y_test[i] != y_pred[i]]\n",
    "misclassified_samples = X_test[misclassified_idx]\n",
    "misclassified_true_labels = y_test[misclassified_idx]\n",
    "misclassified_pred_labels = y_pred[misclassified_idx]\n",
    "\n",
    "# 7. Print misclassified samples and their true vs predicted labels\n",
    "misclassified_df = pd.DataFrame({\n",
    "    'Sample Index': misclassified_idx,\n",
    "    'True Label': misclassified_true_labels,\n",
    "    'Predicted Label': misclassified_pred_labels,\n",
    "    'Sample': list(misclassified_samples)\n",
    "})\n",
    "\n",
    "print(\"\\nMisclassified Samples:\")\n",
    "print(misclassified_df)\n",
    "\n",
    "# 8. Confusion Matrix for better understanding\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ecf4275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 1.00\n",
      "Bagging Classifier Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#14. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train a single Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Train a Bagging Classifier using Decision Trees as base estimator\n",
    "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Make predictions for both models\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "\n",
    "# 6. Calculate accuracy for both models\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "\n",
    "# 7. Print and compare accuracy\n",
    "print(f\"Decision Tree Classifier Accuracy: {accuracy_dt:.2f}\")\n",
    "print(f\"Bagging Classifier Accuracy: {accuracy_bagging:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d100530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#15. Train a Random Forest Classifier and visualize the confusion matrix.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 5. Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 6. Visualize the confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix for Random Forest Classifier')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904176cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 1.00\n",
      "Decision Tree Classifier Accuracy: 1.00\n",
      "SVM Classifier Accuracy: 1.00\n",
      "Logistic Regression Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#16. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Create base models\n",
    "base_learners = [\n",
    "    ('decision_tree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('svm', SVC(probability=True, random_state=42)),\n",
    "    ('logistic_regression', LogisticRegression(random_state=42))\n",
    "]\n",
    "\n",
    "# 4. Create the stacking classifier with a Logistic Regression meta-model\n",
    "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression())\n",
    "\n",
    "# 5. Train the Stacking Classifier\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "\n",
    "# 7. Calculate accuracy for the Stacking Classifier\n",
    "accuracy_stack = accuracy_score(y_test, y_pred_stack)\n",
    "\n",
    "# 8. Train individual models (Decision Tree, SVM, and Logistic Regression) for comparison\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "\n",
    "# 9. Print and compare accuracy for all models\n",
    "print(f\"Stacking Classifier Accuracy: {accuracy_stack:.2f}\")\n",
    "print(f\"Decision Tree Classifier Accuracy: {accuracy_dt:.2f}\")\n",
    "print(f\"SVM Classifier Accuracy: {accuracy_svm:.2f}\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logreg:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c1b67d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Important Features:\n",
      "             Feature  Importance\n",
      "3   petal width (cm)    0.433982\n",
      "2  petal length (cm)    0.417308\n",
      "0  sepal length (cm)    0.104105\n",
      "1   sepal width (cm)    0.044605\n"
     ]
    }
   ],
   "source": [
    "#17. Train a Random Forest Classifier and print the top 5 most important features.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Get feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# 5. Create a DataFrame to store feature names and their importance scores\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# 6. Sort the features by importance in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 7. Print the top 5 most important features\n",
    "print(\"Top 5 Most Important Features:\")\n",
    "print(importance_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24cf35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (Weighted): 1.00\n",
      "Recall (Weighted): 1.00\n",
      "F1-Score (Weighted): 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#18. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train the Bagging Classifier using Decision Trees as base estimators\n",
    "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Make predictions on the test set\n",
    "y_pred = bagging_model.predict(X_test)\n",
    "\n",
    "# 5. Calculate Precision, Recall, and F1-Score for each class\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 6. Print the results\n",
    "print(f\"Precision (Weighted): {precision:.2f}\")\n",
    "print(f\"Recall (Weighted): {recall:.2f}\")\n",
    "print(f\"F1-Score (Weighted): {f1:.2f}\")\n",
    "\n",
    "# 7. Classification Report for more detailed metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36037cae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b22ad9ab6ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mxticks\u001b[1;34m(ticks, labels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1884\u001b[0m                             \"without setting 'ticks'\")\n\u001b[0;32m   1885\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1886\u001b[1;33m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_ticks\u001b[1;34m(self, ticks, labels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m             raise ValueError('labels argument cannot be None when '\n\u001b[0;32m   2122\u001b[0m                              'kwargs are passed')\n\u001b[1;32m-> 2123\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_tick_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2125\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_set_tick_locations\u001b[1;34m(self, ticks, minor)\u001b[0m\n\u001b[0;32m   2075\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshared\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2076\u001b[0m                 \u001b[1;31m# set_view_interval maintains any preexisting inversion.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m                 \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_view_interval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2079\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'NoneType'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#19. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. List of different max_depth values to evaluate\n",
    "max_depth_values = [None, 2, 5, 10, 20, 30, 50]\n",
    "\n",
    "# 4. Store accuracy for each max_depth\n",
    "accuracies = []\n",
    "\n",
    "# 5. Train Random Forest Classifier with different max_depth values and calculate accuracy\n",
    "for max_depth in max_depth_values:\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# 6. Plot the effect of max_depth on accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(max_depth_values, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('Effect of max_depth on Random Forest Accuracy')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(max_depth_values)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 7. Print accuracies for different max_depth values\n",
    "for depth, accuracy in zip(max_depth_values, accuracies):\n",
    "    print(f\"max_depth = {depth}: Accuracy = {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c78440ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Decision Tree Base Estimator): 11312.35\n",
      "Mean Squared Error (KNeighbors Base Estimator): 10652.02\n"
     ]
    }
   ],
   "source": [
    "#20. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance.\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Generate a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=200, n_features=10, noise=0.1, random_state=42)\n",
    "\n",
    "# 2. Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Initialize the Bagging Regressor with different base estimators\n",
    "\n",
    "# Bagging with Decision Tree as base estimator\n",
    "bagging_dt = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=50, random_state=42)\n",
    "bagging_dt.fit(X_train, y_train)\n",
    "y_pred_dt = bagging_dt.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "\n",
    "# Bagging with KNeighbors as base estimator\n",
    "bagging_knn = BaggingRegressor(base_estimator=KNeighborsRegressor(), n_estimators=50, random_state=42)\n",
    "bagging_knn.fit(X_train, y_train)\n",
    "y_pred_knn = bagging_knn.predict(X_test)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "\n",
    "# 4. Print and compare MSE for both models\n",
    "print(f\"Mean Squared Error (Decision Tree Base Estimator): {mse_dt:.2f}\")\n",
    "print(f\"Mean Squared Error (KNeighbors Base Estimator): {mse_knn:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c249a8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "#21. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Get predicted probabilities\n",
    "y_prob = rf_model.predict_proba(X_test)\n",
    "\n",
    "# 5. Binarize the true labels for multi-class ROC AUC calculation\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "\n",
    "# 6. Calculate the ROC-AUC score for each class\n",
    "roc_auc = roc_auc_score(y_test_bin, y_prob, average='macro', multi_class='ovr')\n",
    "\n",
    "# 7. Print the ROC-AUC score\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e70bda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores (Accuracy) for each fold: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
      "Mean Cross-Validation Accuracy: 0.97\n",
      "Standard Deviation of Cross-Validation Accuracy: 0.02\n"
     ]
    }
   ],
   "source": [
    "#22. Train a Bagging Classifier and evaluate its performance using cross-validation.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Initialize the Bagging Classifier using DecisionTreeClassifier as the base estimator\n",
    "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "\n",
    "# 3. Perform cross-validation\n",
    "cv_scores = cross_val_score(bagging_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# 4. Print cross-validation results\n",
    "print(f\"Cross-Validation Scores (Accuracy) for each fold: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {np.mean(cv_scores):.2f}\")\n",
    "print(f\"Standard Deviation of Cross-Validation Accuracy: {np.std(cv_scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c97c888b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#23. Train a Random Forest Classifier and plot the Precision-Recall curv.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Get predicted probabilities\n",
    "y_prob = rf_model.predict_proba(X_test)\n",
    "\n",
    "# 5. Binarize the true labels for multi-class Precision-Recall curve\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "\n",
    "# 6. Plot Precision-Recall curve for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "    plt.plot(recall, precision, label=f'Class {i}')\n",
    "\n",
    "plt.title('Precision-Recall Curve for Random Forest Classifier')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b081e541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Classifier: 1.00\n",
      "Accuracy of Random Forest Classifier: 1.00\n",
      "Accuracy of Logistic Regression: 1.00\n"
     ]
    }
   ],
   "source": [
    "#24. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Initialize the base models for the stacking classifier\n",
    "base_learners = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    ('lr', LogisticRegression(max_iter=200, random_state=42))\n",
    "]\n",
    "\n",
    "# 4. Initialize the Stacking Classifier with Logistic Regression as the final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression())\n",
    "\n",
    "# 5. Train the Stacking Classifier\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions and calculate accuracy\n",
    "y_pred_stacking = stacking_model.predict(X_test)\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "\n",
    "# 7. Train and evaluate a Random Forest Classifier for comparison\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# 8. Train and evaluate Logistic Regression for comparison\n",
    "lr_model = LogisticRegression(max_iter=200, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# 9. Print the comparison of accuracies\n",
    "print(f\"Accuracy of Stacking Classifier: {accuracy_stacking:.2f}\")\n",
    "print(f\"Accuracy of Random Forest Classifier: {accuracy_rf:.2f}\")\n",
    "print(f\"Accuracy of Logistic Regression: {accuracy_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6134d79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max samples: 0.5, Mean Squared Error: 12543.20\n",
      "Max samples: 0.7, Mean Squared Error: 11610.61\n",
      "Max samples: 1.0, Mean Squared Error: 11312.35\n",
      "\n",
      "Best Max Samples: 1.0 with MSE: 11312.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#25. Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 1. Generate a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=200, n_features=10, noise=0.1, random_state=42)\n",
    "\n",
    "# 2. Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train Bagging Regressors with different max_samples (levels of bootstrap samples)\n",
    "max_samples_values = [0.5, 0.7, 1.0]  # Different levels of bootstrap samples\n",
    "\n",
    "mse_scores = []  # To store the MSE for each max_samples value\n",
    "\n",
    "for max_samples in max_samples_values:\n",
    "    # Create Bagging Regressor with DecisionTreeRegressor as base estimator\n",
    "    bagging_model = BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n",
    "                                     n_estimators=50,\n",
    "                                     max_samples=max_samples,\n",
    "                                     random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate MSE\n",
    "    y_pred = bagging_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "    print(f\"Max samples: {max_samples}, Mean Squared Error: {mse:.2f}\")\n",
    "\n",
    "# 4. Compare performance (MSE)\n",
    "best_mse = min(mse_scores)\n",
    "best_max_samples = max_samples_values[mse_scores.index(best_mse)]\n",
    "\n",
    "print(f\"\\nBest Max Samples: {best_max_samples} with MSE: {best_mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194cca88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
